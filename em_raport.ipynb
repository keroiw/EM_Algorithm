{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metody klasyfikacji i redukcji wymiaru\n",
    "\n",
    "### Zastosowanie algorytmu EM do uproszczonej wersji znajdowania motywów w ciągach DNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Błażej Wiórek, Zofia Dziedzic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opis problemu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obserwujemy wektor losowy $\\mathbf{X} = (X_1, X_2, \\ldots, X_w)$, taki że $X_1, X_2, \\ldots, X_w$ są niezależne o rozkładzie\n",
    "\n",
    "$$\n",
    "    p(x_i; \\mathbf{\\theta_i}) = \\theta_{1i}\\mathbb{1}_{\\{1\\}}(x_i) + \\theta_{2i}\\mathbb{1}_{\\{2\\}}(x_i) + \\theta_{3i}\\mathbb{1}_{\\{3\\}}(x_i) + \\theta_{4i}\\mathbb{1}_{\\{4\\}}(x_i),\n",
    "$$\n",
    "\n",
    "gdzie $\\mathbf{\\theta_i} = (\\theta_{1i}, \\theta_{2i}, \\theta_{3i}, \\theta_{4i})^T$. Oznacza to, że zmienne $X_i$, $i \\in \\{1,2,\\ldots,w\\}$ przyjmują wartości ze zbioru $\\{1,2,3,4\\}$ odpowiednio z prawdopodobieństwami $\\theta_{1i}, \\theta_{2i}, \\theta_{3i}, \\theta_{4i}$. Wobec tego\n",
    "\n",
    "$$\n",
    "    p(\\mathbf{x}; \\mathbf{\\theta}) = \\prod_{i=1}^{w} p(x_i; \\mathbf{\\theta_i}).\n",
    "$$\n",
    "\n",
    "Naszym zadaniem będzie modelowanie tego wektora w sytuacji, gdy $\\mathbf{\\theta_i}, i = 1, 2, \\ldots, w$ może przyjmować jedną z dwóch postaci\n",
    "\n",
    "$$\n",
    "    \\boldsymbol{\\theta^{(0)}_i} = (\\theta^{(0)}_{1i}, \\theta^{(0)}_{2i}, \\theta^{(0)}_{3i}, \\theta^{(0)}_{4i})^T,\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\boldsymbol{\\theta^{(1)}_i} = (\\theta^{(1)}_{1i}, \\theta^{(1)}_{2i}, \\theta^{(1)}_{3i}, \\theta^{(1)}_{4i})^T.\n",
    "$$\n",
    "\n",
    "Oznaczmy przez $\\mathbf\\Theta^{(0)}$ macierz, której elementami są $\\theta^{(0)}_{ki}$, $k = 1,2,3,4$ i, analogicznie, $\\mathbf\\Theta^{(1)} = (\\mathbf\\theta^{(1)}_1, \\theta^{(1)}_2, \\ldots, \\theta^{(1)}_w)$.\n",
    "O tym, z którego z rozkładów - $p(\\mathbf{x}; \\mathbf\\theta^{(0)})$ czy $p(\\mathbf{x}; \\mathbf\\theta^{(1)})$ - pochodzi $X$, decyduje inna zmienna losowa, $Z$, która z p-stwem $\\alpha_0$ jest równa $0$ i z p-stwem $\\alpha_1 = 1 - \\alpha_0$ jest równa $1$.\n",
    "Niech\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_1 = x_{11}, x_{12}, \\ldots, x_{1i}, \\ldots, x_{1w} \\\\\n",
    "\\mathbf{x}_2 = x_{21}, x_{22}, \\ldots, x_{2i}, \\ldots, x_{2w} \\\\\n",
    "\\ldots \\\\\n",
    "\\mathbf{x}_j = x_{j1}, x_{j2}, \\ldots, x_{ji}, \\ldots, x_{jw} \\\\\n",
    "\\ldots \\\\\n",
    "\\mathbf{x}_k = x_{k1}, x_{k2}, \\ldots, x_{ki}, \\ldots, x_{kw}\n",
    "$$\n",
    "\n",
    "będą zaobserwowanymi niezależnymi realizacjami wektora losowego $\\mathbf{X}$. Każdej z nich odpowiada $z_j$, $j = 1, \\ldots, k$, które decyduje o rozkładzie $X_j$.\n",
    "\n",
    "W oparciu o daną próbę, ale nie znając wartości $z_1, \\ldots, z_k$, chcemy wyestymować parametry $\\mathbf{\\Theta} = (\\mathbf\\Theta^{(0)}, \\mathbf\\Theta^{(1)})$ i $\\alpha = (\\alpha_0, \\alpha_1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja wiarogodności"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametrów $\\hat{\\mathbf{\\Theta}}$ i $\\hat\\alpha$ będziemy szukać, maksymalizując logarytm funkcji wiarogodności\n",
    "$$\n",
    "l(\\mathbf{\\Theta},\\alpha) = \\log L(\\mathbf{\\Theta}, \\alpha) = \\sum_{j=1}^k \\log p(\\mathbf{x_j}, z_j; \\mathbf{\\Theta}, \\alpha) = \n",
    " \\sum_{j=1}^k \\log (p(\\mathbf{x_j}, \\mathbf\\Theta^{(0)})\\alpha_0 + p(\\mathbf{x_j}, \\mathbf\\Theta^{(1)})\\alpha_1).\n",
    "$$\n",
    "\n",
    "Ponieważ nie jesteśmy w stanie znaleźć estymatorów największej wiarogodności analitycznie, użyjemy w tym celu algorytmu EM, który opisujemy krótko poniżej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorytm EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea tej procedury opiera się na fakcie, że dla znanego $\\mathbf{z} = (z_1, z_2, \\ldots, z_k)^T$ łatwo znaleźć $\\hat{\\mathbf{\\Theta}}$ i $\\hat \\alpha$. Algorytm składa się więc z następujących dwóch kroków, które po odpowiedniej liczbie iteracji pozwalają skutecznie wyestymować szukane parametry:\n",
    "\n",
    "   1. **Expectation**\n",
    "    \n",
    "   \"Zgadnięcie\" $\\mathbf{z}$, które w praktyce polega na obliczeniu \"wag\" $\\mathbf{w^0} = (w_0^{(1)},\\ldots,w_0^{(k)})$, \n",
    "   $\\mathbf{w^1} = (w^1_{(1)},\\ldots,w^1_{(k)})$, takich że\n",
    "   \n",
    "   $$\n",
    "   w^0_{(j)} = \\mathbb{P}(z_j = 0|\\mathbf{X_j} = \\mathbf{x_j}; \\mathbf{\\Theta}) = \n",
    "   \\frac{\\mathbb{P}(\\mathbf{X_j} = \\mathbf{x_j}|z_j = 0; \\mathbf{\\Theta^{(0)})}\\alpha_0}{\\mathbb{P}(\\mathbf{X_j} = \\mathbf{x_j}|z_j = 0; \\mathbf{\\Theta^{(0)})}\\alpha_0 + \\mathbb{P}(\\mathbf{X_j} = \n",
    "   \\mathbf{x_j}|z_j = 1; \\mathbf{\\Theta^{(1)})}\\alpha_1} =\n",
    "   \\frac{\\prod_{i=1}^{w}\\theta^{(0)}_{x_{ji}}\\alpha_0}{\\prod_{i=1}^{w}\\theta^{(0)}_{x_{ji}}\\alpha_0 + \\prod_{i=1}^{w}\\theta^{(1)}_{x_{ji}}\\alpha_1}\n",
    "   $$\n",
    "   i\n",
    "    $$\n",
    "   w^1_{(j)} = \\mathbb{P}(z_j = 1|\\mathbf{X_j} = \\mathbf{x_j}; \\mathbf{\\Theta}) = \n",
    "   \\frac{\\mathbb{P}(\\mathbf{X_j} = \\mathbf{x_j}|z_j = 1; \\mathbf{\\Theta^{(1)})}\\alpha_1}\n",
    "   {\\mathbb{P}(\\mathbf{X_j} = \\mathbf{x_j}|z_j = 0; \\mathbf{\\Theta^{(0)}})\\alpha_0 \n",
    "   + \\mathbb{P}(\\mathbf{X_j} = \\mathbf{x_j}|z_j = 1; \\mathbf{\\Theta^{(1)}})\\alpha_1} = \n",
    "   \\frac{\\prod_{i=1}^{w}\\theta^{(1)}_{x_{ji}}\\alpha_1}{\\prod_{i=1}^{w}\\theta^{(0)}_{x_{ji}}\\alpha_0 +\n",
    "   \\prod_{i=1}^{w}\\theta^{(1)}_{x_{ji}}\\alpha_1}.\n",
    "   $$\n",
    "   \n",
    "   2. **Maximization**\n",
    "   \n",
    "   Wyliczenie, dla danych $\\mathbf{w^0}$ i $\\mathbf{w^1}$,\n",
    "   \n",
    "   $$ \n",
    "   \\hat{\\theta}^{(0)}_{1i} = \\frac{\\sum_{j=1}^k w^0_{(j)}\\mathbb{1}_{\\{1\\}}(x_{ji})}{\\sum_{j=1}^k w^0_{(j)}},\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   \\vdots \\\\\n",
    "   \\hat{\\theta}^{(0)}_{4i} = \\frac{\\sum_{j=1}^k w^0_{(j)}\\mathbb{1}_{\\{4\\}}(x_{ji})}{\\sum_{j=1}^k w^0_{(j)}},\n",
    "   $$\n",
    "   \n",
    "   $$ \n",
    "   \\hat{\\theta}^{(1)}_{1i} = \\frac{\\sum_{j=1}^k w^1_{(j)}\\mathbb{1}_{\\{1\\}}(x_{ji})}{\\sum_{j=1}^k w^1_{(j)}},\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   \\vdots \\\\\n",
    "   \\hat{\\theta}^{(1)}_{4i} = \\frac{\\sum_{j=1}^k w^1_{(j)}\\mathbb{1}_{\\{4\\}}(x_{ji})}{\\sum_{j=1}^k w^1_{(j)}},\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   \\hat{\\alpha}_0 = \\frac{1}{k}\\sum_{j=1}^k w^0_j,\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   \\hat{\\alpha}_1 = 1 - \\hat{\\alpha}_0.\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generowanie danych i implementacja algorytmu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program, który stworzyliśmy, dla zadanych parametrów $w, k, \\mathbf\\Theta^{(0)}, \\mathbf\\Theta^{(1)}$ i wygenerowanego na ich podstawie $\\mathbf{X} \\in \\{1,2,3,4\\}^{w\\times k}$, oblicza za pomocą EM $\\hat{\\mathbf{\\Theta}}$ i $\\hat{\\alpha}$. W drugiej wersji, gdy parametr `--estimate_alpha` jest równy `no`, dla zadanego $\\alpha$ estymujemy jedynie $\\mathbf\\Theta^{(0)}, \\mathbf\\Theta^{(1)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "theta_a = np.random.rand(10*4).reshape((4, 10))\n",
    "theta_a = theta_a/np.sum(theta_a, axis=0)\n",
    "\n",
    "theta_b = np.random.rand(10*4).reshape((4, 10))\n",
    "theta_b = theta_b/np.sum(theta_b, axis=0)\n",
    "\n",
    "params = {\n",
    "    \"w\" : 10,\n",
    "    \"alpha\" : 0.5,\n",
    "    \"k\" : 10000,\n",
    "    \"Theta\" : theta_a.tolist(),\n",
    "    \"ThetaB\" : theta_b.tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    w = params['w']\n",
    "    k = params['k']\n",
    "    alpha = params['alpha']\n",
    "\n",
    "    theta_a = np.array(params['Theta'])\n",
    "    theta_b = np.array(params['ThetaB'])\n",
    "    X = np.zeros((k, w))\n",
    "    for i in range(k):\n",
    "        distr = theta_a\n",
    "        if random.random() < alpha:\n",
    "            distr = theta_b\n",
    "        X[i, :] = [np.random.choice([1, 2, 3, 4], size=1, p=distr[:, i]) for i in range(w)]\n",
    "\n",
    "    return {\n",
    "        \"alpha\": alpha,\n",
    "        \"X\": X\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "class AlgorithmStateBase:\n",
    "    __slots__ = ['theta_a', 'theta_b']\n",
    "\n",
    "    def __init__(self, theta_a, theta_b):\n",
    "        self.theta_a = theta_a\n",
    "        self.theta_b = theta_b\n",
    "\n",
    "    @staticmethod\n",
    "    def compare(obj1, obj2, thresh=10e-2):\n",
    "        theta_a1 = obj1.theta_a.flatten()\n",
    "        theta_a2 = obj1.theta_a.flatten()\n",
    "        theta_b1 = obj2.theta_b.flatten()\n",
    "        theta_b2 = obj2.theta_b.flatten()\n",
    "        theta_a_norm = np.linalg.norm(theta_a1 - theta_a2) < thresh\n",
    "        theta_b_norm = np.linalg.norm(theta_b1 - theta_b2) < thresh\n",
    "        return isinstance(obj1, AlgorithmStateInit) or all(np.array([theta_a_norm, theta_b_norm]) > thresh)\n",
    "\n",
    "\n",
    "class AlgorithmStateInit(AlgorithmStateBase):\n",
    "\n",
    "    def __init__(self, w):\n",
    "        super().__init__(np.zeros((4, w)), np.zeros((4, w)))\n",
    "\n",
    "\n",
    "class AlgorithmState(AlgorithmStateBase):\n",
    "\n",
    "    def __init__(self, theta_a, theta_b):\n",
    "        super().__init__(theta_a, theta_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_distr(w):\n",
    "    theta = np.random.rand(4*w).reshape((4, -1))\n",
    "    theta_sum = np.sum(theta, axis=0)\n",
    "    return theta/theta_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation(X: np.array, alpha, theta_a, theta_b):\n",
    "\n",
    "    def get_cond_prob(X, theta):\n",
    "        cond_prob = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            x_i = X[i, :]\n",
    "            x_i_prob = [theta[j-1, k] for k, j in zip(range(theta.shape[1]), x_i)]\n",
    "            cond_prob[i] = reduce(lambda x, y: x * y, x_i_prob)\n",
    "        return cond_prob\n",
    "\n",
    "    cond_1 = get_cond_prob(X, theta_a)\n",
    "    cond_2 = get_cond_prob(X, theta_b)\n",
    "    weights_mtrx = np.vstack((cond_1, cond_2)).T\n",
    "    alphas = np.array([alpha, 1 - alpha])\n",
    "    cond_sums = weights_mtrx @ alphas.reshape((2, 1))\n",
    "    weights_mtrx[:, 0] = (alpha * weights_mtrx[:, 0]) / cond_sums.flatten()\n",
    "    weights_mtrx[:, 1] = ((1 - alpha) * weights_mtrx[:, 1]) / cond_sums.flatten()\n",
    "\n",
    "    return weights_mtrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_new(X, weights):\n",
    "    N_k = np.sum(weights, axis=0)\n",
    "    return 1-(N_k / np.sum(N_k))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_theta(X_full, weights_full):\n",
    "\n",
    "    def get_estimators(k):\n",
    "        weights = weights_full[:, k]\n",
    "        estimators = []\n",
    "        for i in range(X_full.shape[1]):\n",
    "            labels_pred = [X_full[:, i] == k for k in range(1, 5)]\n",
    "            label_sums = np.array([np.sum(weights[pred]) for pred in labels_pred])\n",
    "            estimators.append(label_sums / np.sum(weights))\n",
    "        return np.array(estimators).T\n",
    "\n",
    "    estimators_1 = get_estimators(0)\n",
    "    estimators_2 = get_estimators(1)\n",
    "\n",
    "    return estimators_1, estimators_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_em(X: pd.Series, w: int):\n",
    "    alpha = 0.5\n",
    "    theta_a, theta_b = init_distr(w), init_distr(w)\n",
    "\n",
    "    alg_state_old = AlgorithmStateInit(w)\n",
    "    alg_state_new = AlgorithmStateInit(w)\n",
    "    counter = 1\n",
    "    while AlgorithmState.compare(alg_state_old, alg_state_new) and counter < 100:\n",
    "        weights = expectation(X, alpha, theta_a, theta_b)\n",
    "        # alpha = alpha_new(X, weights)\n",
    "        theta_a, theta_b = new_theta(X, weights)\n",
    "\n",
    "        alg_state_old = alg_state_new\n",
    "        alg_state_new = AlgorithmState(theta_a, theta_b)\n",
    "        counter += 1\n",
    "\n",
    "    return theta_a, theta_b, alpha, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_data()[\"X\"].astype(int)\n",
    "theta_a_est, theta_b_est, alpha, counter = init_em(X, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wyniki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej przedstawiamy wyniki estymacji dla $w=10$, $k=10000$ i $\\alpha = 0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf\\Theta^{(0)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.433 0.319 0.268 0.267 0.31  0.563 0.052 0.257 0.364 0.28 ]\n",
      " [0.467 0.128 0.25  0.058 0.294 0.197 0.501 0.195 0.309 0.204]\n",
      " [0.056 0.487 0.345 0.339 0.04  0.194 0.29  0.359 0.217 0.001]\n",
      " [0.044 0.065 0.137 0.336 0.357 0.045 0.157 0.188 0.109 0.515]]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(theta_a,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{\\mathbf\\Theta}^{(0)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.491 0.213 0.305 0.332 0.405 0.211 0.186 0.242 0.285 0.158]\n",
      " [0.174 0.257 0.352 0.162 0.116 0.244 0.327 0.355 0.322 0.279]\n",
      " [0.225 0.499 0.182 0.239 0.052 0.248 0.269 0.318 0.114 0.068]\n",
      " [0.111 0.031 0.16  0.268 0.427 0.296 0.218 0.085 0.279 0.496]]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(theta_a_est,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf\\Theta^{(1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.491 0.214 0.308 0.322 0.415 0.195 0.186 0.235 0.284 0.155]\n",
      " [0.17  0.246 0.355 0.162 0.116 0.252 0.34  0.357 0.318 0.278]\n",
      " [0.22  0.507 0.179 0.261 0.054 0.261 0.263 0.334 0.11  0.065]\n",
      " [0.118 0.033 0.158 0.256 0.415 0.292 0.211 0.075 0.288 0.502]]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(theta_b, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{\\mathbf\\Theta}^{(1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.424 0.332 0.273 0.256 0.308 0.551 0.056 0.258 0.354 0.289]\n",
      " [0.469 0.124 0.241 0.057 0.289 0.208 0.495 0.196 0.315 0.19 ]\n",
      " [0.056 0.479 0.351 0.362 0.036 0.193 0.295 0.368 0.218 0.   ]\n",
      " [0.05  0.065 0.136 0.325 0.367 0.047 0.154 0.179 0.113 0.521]]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(theta_b_est,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "w = params['w']\n",
    "\n",
    "norms_a = []\n",
    "norms_b = []\n",
    "\n",
    "for i in range(w):\n",
    "    norms_a.append(np.linalg.norm(theta_a.T[i] - theta_a_est.T[i]))\n",
    "    norms_b.append(np.linalg.norm(theta_b.T[i] - theta_b_est.T[i]))\n",
    "\n",
    "\n",
    "plt.plot(range(w), norms_a, 'g.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(w), norms_b, 'g.')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
